{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Требуемое значение метрики качества *F1* - не меньше 0.75. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим и прочитаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "data.info()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем распоряжении датафрейм из двух столбцов и 159292 строк. В столбце ```text``` содержатся комментарии, а в столбце ```toxic``` метка - 1, если комментарий токсичного содержания и 0 в противном случае. Проверим, есть ли пропуски и дубликаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в данных:\n",
      "text     0\n",
      "toxic    0\n",
      "dtype: int64\n",
      "\n",
      "Количество дубликатов: 0\n"
     ]
    }
   ],
   "source": [
    "def check_data(data):\n",
    "    # Проверка на пропуски\n",
    "    missing_data = data.isnull().sum()\n",
    "    \n",
    "    # Проверка на дубликаты\n",
    "    duplicate_count = data.duplicated().sum()\n",
    "    \n",
    "    return missing_data, duplicate_count\n",
    "\n",
    "missing_data, duplicate_count = check_data(data)\n",
    "print(\"Пропуски в данных:\")\n",
    "print(missing_data)\n",
    "print(\"\\nКоличество дубликатов:\", duplicate_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков в данных не обнаружено, дубликаты также отсутствуют. Можно переходить к предобработке данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cant make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>and i really dont think you understand i came...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       explanation why the edits made under my userna...      0\n",
       "1       daww he matches this background colour im seem...      0\n",
       "2       hey man im really not trying to edit war its j...      0\n",
       "3        more i cant make any real suggestions on impr...      0\n",
       "4       you sir are my hero any chance you remember wh...      0\n",
       "...                                                   ...    ...\n",
       "159446  and for the second time of asking when your vi...      0\n",
       "159447  you should be ashamed of yourself that is a ho...      0\n",
       "159448  spitzer umm theres no actual article for prost...      0\n",
       "159449  and it looks like it was actually you who put ...      0\n",
       "159450   and i really dont think you understand i came...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Заменяем символы переноса строки пробелами\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Удаляем все символы, кроме букв и пробелов\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Удаляем все лишние пробелы (где их по несколько штук подряд)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Приводим текст к нижнему регистру\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Применяем функцию\n",
    "data['text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Смотрим, что получилось\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лишние символы исчезли, текст перешёл в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww he match this background colour im seemin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really not try to edit war it just ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cant make any real suggestion on improv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>spitzer umm there no actual article for prosti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>and i really dont think you understand i come ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       explanation why the edits make under my userna...      0\n",
       "1       daww he match this background colour im seemin...      0\n",
       "2       hey man im really not try to edit war it just ...      0\n",
       "3       more i cant make any real suggestion on improv...      0\n",
       "4       you sir be my hero any chance you remember wha...      0\n",
       "...                                                   ...    ...\n",
       "159446  and for the second time of ask when your view ...      0\n",
       "159447  you should be ashamed of yourself that be a ho...      0\n",
       "159448  spitzer umm there no actual article for prosti...      0\n",
       "159449  and it look like it be actually you who put on...      0\n",
       "159450  and i really dont think you understand i come ...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем список стоп-слов\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Создаем функцию для лемматизации текста с учетом частей речи\n",
    "def lemmatize_text_with_pos(text):\n",
    "    def get_wordnet_pos(tag):\n",
    "        tag = tag[0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(pos_tag([word])[0][1])) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Применяем функцию лемматизации к столбцу с текстами\n",
    "data['text'] = data['text'].apply(lemmatize_text_with_pos)\n",
    "\n",
    "# Смотрим, что получилось\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация проведена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Мы успешно провели предобработку текстов, включая удаление символов новой строки, удаление лишних символов, удаление лишних пробелов, приведение к нижнему регистру и лемматизацию текста с учетом частей речи. Теперь данные готовы к использованию для обучения модели классификации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143106\n",
      "1     16186\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_balance = data['toxic'].value_counts()\n",
    "print(class_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас имеет место дисбаланс классов, где класс 0 (нет токсичности) имеет намного больше экземпляров, чем класс 1 (токсичные комментарии). Для решения этой проблемы с дисбалансом классов можно использовать различные стратегии. Одной из них является взвешивание классов при обучении модели.\n",
    "\n",
    "Воспользуемся параметром ```class_weight``` в моделях машинного обучения. Он позволяет установить веса классов, которые учитывают дисбаланс. Веса будут выставлены так, чтобы класс 1 (токсичные комментарии) имел больший вес, чем класс 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "features = data['text']\n",
    "target = data['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=1337, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приступим к обучению моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры и оценки F1 для логистической регрессии:\n",
      "{'model__C': 10, 'model__max_iter': 250, 'model__solver': 'liblinear'}\n",
      "Лучший F1 Score для логистической регрессии: 0.7561318165467771\n",
      "Лучшие параметры и оценки F1 для Decision Tree:\n",
      "{'model__max_depth': None, 'model__min_samples_split': 2}\n",
      "Лучший F1 Score для Decision Tree: 0.6032850107846731\n",
      "Лучшие параметры и оценки F1 для Random Forest:\n",
      "{'model__max_depth': None, 'model__n_estimators': 200}\n",
      "Лучший F1 Score для Random Forest: 0.5923569397364705\n",
      "Лучшая модель: Logistic Regression\n",
      "Лучшие гиперпараметры: {'model__C': 10, 'model__max_iter': 250, 'model__solver': 'liblinear'}\n",
      "CPU times: user 2h 3min 24s, sys: 1min 30s, total: 2h 4min 55s\n",
      "Wall time: 2h 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Логистическая регрессия\n",
    "lr_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('model', LogisticRegression(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "lr_params = {\n",
    "    'model__solver': ['liblinear'],\n",
    "    'model__C': [0.1, 1, 10],\n",
    "    'model__max_iter': [250]\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(lr_pipeline, lr_params, cv=3, scoring='f1', n_jobs=-1)\n",
    "lr_grid.fit(features_train, target_train)\n",
    "\n",
    "# Decision Tree\n",
    "dt_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('model', DecisionTreeClassifier(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "dt_params = {\n",
    "    'model__max_depth': [None, 2, 12, 24],\n",
    "    'model__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(dt_pipeline, dt_params, cv=3, scoring='f1', n_jobs=-1)\n",
    "dt_grid.fit(features_train, target_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('model', RandomForestClassifier(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "rf_params = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(rf_pipeline, rf_params, cv=3, scoring='f1', n_jobs=-1)\n",
    "rf_grid.fit(features_train, target_train)\n",
    "\n",
    "# Получение лучших параметров и оценки F1 для каждой модели\n",
    "best_lr_params = lr_grid.best_params_\n",
    "best_lr_f1_score = lr_grid.best_score_\n",
    "\n",
    "best_dt_params = dt_grid.best_params_\n",
    "best_dt_f1_score = dt_grid.best_score_\n",
    "\n",
    "best_rf_params = rf_grid.best_params_\n",
    "best_rf_f1_score = rf_grid.best_score_\n",
    "\n",
    "print(\"Лучшие параметры и оценки F1 для логистической регрессии:\")\n",
    "print(best_lr_params)\n",
    "print(\"Лучший F1 Score для логистической регрессии:\", best_lr_f1_score)\n",
    "\n",
    "print(\"Лучшие параметры и оценки F1 для Decision Tree:\")\n",
    "print(best_dt_params)\n",
    "print(\"Лучший F1 Score для Decision Tree:\", best_dt_f1_score)\n",
    "\n",
    "print(\"Лучшие параметры и оценки F1 для Random Forest:\")\n",
    "print(best_rf_params)\n",
    "print(\"Лучший F1 Score для Random Forest:\", best_rf_f1_score)\n",
    "\n",
    "# Находим модель с наилучшими параметрами\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "best_params = None\n",
    "best_f1_score = -1\n",
    "\n",
    "for model_name, grid_result in [('Logistic Regression', lr_grid), ('Decision Tree', dt_grid), ('Random Forest', rf_grid)]:\n",
    "    if grid_result.best_score_ > best_f1_score:\n",
    "        best_model = grid_result.best_estimator_\n",
    "        best_model_name = model_name\n",
    "        best_params = grid_result.best_params_\n",
    "        best_f1_score = grid_result.best_score_\n",
    "\n",
    "# Выводим имя лучшей модели и её гиперпараметры\n",
    "print(\"Лучшая модель:\", best_model_name)\n",
    "print(\"Лучшие гиперпараметры:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из трёх моделей только Логистическая Регрессия достигла необходимого результата по f1-мере (0.75). Её f1 составила 0.756. Теперь модель нужно проверить на тестовой выборке, и в случае, если результат не будет хуже, чем 0.75, можно считать эту модель подходящей для наших задач."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score на тестовой выборке: 0.7599942685198452\n"
     ]
    }
   ],
   "source": [
    "# Проверка лучшей модели на тестовой выборке\n",
    "test_predictions = best_model.predict(features_test)\n",
    "test_f1_score = f1_score(target_test, test_predictions)\n",
    "\n",
    "print(\"F1 Score на тестовой выборке:\", test_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение f1 на тестовой выборке составило 0.76, что позволяет сделать вывод, что данная модель полностью отвечает нашим требованиям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках данного проекта были выполнены следующие этапы:\n",
    "\n",
    "1. Загрузка данных: Начальным шагом было считывание данных из файла 'toxic_comments.csv' с помощью библиотеки Pandas. Выведена общая информация о данных для оценки объема и качества данных.\n",
    "\n",
    "2. Предобработка данных: Проведена предобработка текстовых данных, включая удаление символов новой строки, удаление лишних символов, приведение текста к нижнему регистру, и лемматизация текста с учетом частей речи. Также создан список стоп-слов для английского языка.\n",
    "\n",
    "3. Балансировка классов: Обнаружен дисбаланс классов в целевой переменной и применена балансировка классов для моделей.\n",
    "\n",
    "4. Разделение данных: Данные были разделены на обучающую и тестовую выборки. При этом был соблюдён одинаковый баланс классов в обоих выборках.\n",
    "\n",
    "5. Обучение моделей: Обучены три различные модели - логистическая регрессия, дерево решений и случайный лес, с использованием метода кросс-валидации и GridSearchCV для подбора оптимальных гиперпараметров. Для каждой модели подобраны наилучшие параметры и вычислен F1 Score на обучающей выборке.\n",
    "\n",
    "6. Тестирование модели: Лучшая модель, в данном случае логистическая регрессия, была протестирована на тестовой выборке. Полученный F1 Score на тестовых данных составил 0.760, что удовлетворяет требованиям проекта (F1 Score не менее 0.75).\n",
    "\n",
    "Таким образом, проект успешно выполнен, и модель готова к использованию для классификации токсичных комментариев в интернет-магазине \"Викишоп\"."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1396,
    "start_time": "2023-10-30T13:39:45.975Z"
   },
   {
    "duration": 2772,
    "start_time": "2023-10-30T13:40:09.375Z"
   },
   {
    "duration": 1030,
    "start_time": "2023-10-30T13:43:10.337Z"
   },
   {
    "duration": 257,
    "start_time": "2023-10-30T13:50:02.099Z"
   },
   {
    "duration": 343,
    "start_time": "2023-10-30T13:54:11.790Z"
   },
   {
    "duration": 4883,
    "start_time": "2023-10-30T13:57:09.752Z"
   },
   {
    "duration": 4011,
    "start_time": "2023-10-30T13:58:47.714Z"
   },
   {
    "duration": 567,
    "start_time": "2023-10-30T14:09:03.986Z"
   },
   {
    "duration": 12097,
    "start_time": "2023-10-30T14:19:17.964Z"
   },
   {
    "duration": 1110089,
    "start_time": "2023-10-30T14:19:54.334Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-30T14:46:20.457Z"
   },
   {
    "duration": 28,
    "start_time": "2023-10-30T15:13:27.571Z"
   },
   {
    "duration": 5139369,
    "start_time": "2023-10-30T15:14:09.099Z"
   },
   {
    "duration": 1703,
    "start_time": "2023-10-30T16:42:48.664Z"
   },
   {
    "duration": 1050,
    "start_time": "2023-10-30T16:42:50.369Z"
   },
   {
    "duration": 248,
    "start_time": "2023-10-30T16:42:51.420Z"
   },
   {
    "duration": 4768,
    "start_time": "2023-10-30T16:42:51.670Z"
   },
   {
    "duration": 1610,
    "start_time": "2023-10-30T16:43:51.656Z"
   },
   {
    "duration": 1030,
    "start_time": "2023-10-30T16:43:53.267Z"
   },
   {
    "duration": 260,
    "start_time": "2023-10-30T16:43:54.299Z"
   },
   {
    "duration": 4687,
    "start_time": "2023-10-30T16:43:54.561Z"
   },
   {
    "duration": 1096949,
    "start_time": "2023-10-30T16:43:59.251Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-30T17:02:16.202Z"
   },
   {
    "duration": 120,
    "start_time": "2023-10-30T17:02:16.208Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-30T17:02:16.330Z"
   },
   {
    "duration": 60,
    "start_time": "2023-10-30T20:01:15.396Z"
   },
   {
    "duration": 35772314,
    "start_time": "2023-10-30T20:01:24.938Z"
   },
   {
    "duration": 467,
    "start_time": "2023-10-31T05:57:51.356Z"
   },
   {
    "duration": 7501090,
    "start_time": "2023-10-31T06:01:59.952Z"
   },
   {
    "duration": 1506,
    "start_time": "2023-10-31T08:20:04.044Z"
   },
   {
    "duration": 180,
    "start_time": "2023-10-31T08:30:46.344Z"
   },
   {
    "duration": 21,
    "start_time": "2023-10-31T08:30:54.584Z"
   },
   {
    "duration": 17,
    "start_time": "2023-10-31T08:34:04.141Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-31T08:34:15.126Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-31T08:39:16.223Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
